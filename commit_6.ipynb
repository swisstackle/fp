{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b69e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06ae6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose=mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a9f1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7aef9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.array(['good left half','good right half','bad left half', 'bad right half'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3367ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q=['lr.mp4','rl1.mp4','rl2.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0beaf350",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(r'C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training Videos Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce4f76b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\surya\\\\OneDrive\\\\Desktop\\\\Sem 2 UB\\\\ML_Exp\\\\fp\\\\Training Videos Final'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcb2e6",
   "metadata": {},
   "source": [
    "# something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e2a1654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good left half', 'good right half', 'bad left half',\n",
       "       'bad right half'], dtype='<U15')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26acd873",
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in out:\n",
    "    os.makedirs(os.path.join(DATA_PATH,out))\n",
    "    for i in range(8):\n",
    "        os.makedirs(os.path.join(DATA_PATH, out,str(i)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adccf886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad right half'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdb940c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q_1 = os.listdir(r'C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training_Videos_Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "500c4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_i=r'C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training_Videos_Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5234c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good left half'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_q_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86b542dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid_q_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc0c0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x):\n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        y=os.path.join(r'C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training_Videos_Final', str(x[i]))\n",
    "        print(y)\n",
    "        lab_vid_l=os.listdir(y)\n",
    "        #print(lab_vid_l)\n",
    "        for vid in lab_vid_l:\n",
    "            #print(vid)\n",
    "            cap = cv2.VideoCapture(str(vid))\n",
    "            # used to record the time when we processed last frame\n",
    "            prev_frame_time = 0\n",
    "\n",
    "            # used to record the time at which we processed current frame\n",
    "            new_frame_time = 0\n",
    "            # VIDEO FEED\n",
    "\n",
    "            with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "                differenceHipsList = [];differenceShouldersList = [];\n",
    "                leftshoulderList = [];rightshoulderList = [];\n",
    "                lsp=[];rsp=[];lhp=[];rhp=[];lefthipList = [];\n",
    "                righthipList = [];midpointsholder_l=[];\n",
    "                midpointhip_l=[]\n",
    "                spinelength_l=[]\n",
    "                s_len=[]\n",
    "                h_len=[]\n",
    "                ratio_l=[]\n",
    "                framecounter = 0\n",
    "                d=0\n",
    "                #print('a')\n",
    "                cap.open(str(vid))\n",
    "                while cap.isOpened(): \n",
    "                    print('f')\n",
    "                    ret, frame = cap.read()\n",
    "                    print('g')\n",
    "                    if not ret:\n",
    "                        print('a')\n",
    "                        break\n",
    "                    if frame is not None:\n",
    "                        print('b')\n",
    "                        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                        image.flags.writeable = False\n",
    "                        results = pose.process(image)\n",
    "                        image.flags.writeable = True\n",
    "                        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "                        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                        new_frame_time = time.time()\n",
    "                    # Calculating the fps\n",
    "\n",
    "                    # fps will be number of frame processed in given time frame\n",
    "                    # since their will be most of time error of 0.001 second\n",
    "                    # we will be subtracting it to get more accurate result\n",
    "                        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "                        prev_frame_time = new_frame_time\n",
    "\n",
    "                    # converting the fps into integer\n",
    "                        fps = int(fps)\n",
    "\n",
    "                    # converting the fps to string so that we can display it on frame\n",
    "                    # by using putText function\n",
    "                        fps_1 = str(fps)\n",
    "\n",
    "                    # putting the FPS count on the frame\n",
    "                        cv2.putText(image, fps_1, (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "                        try:\n",
    "                            landmarks = results.pose_landmarks.landmark\n",
    "                            leftshoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "                            rightshoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "                            differenceShoulders = np.absolute(rightshoulder.z - leftshoulder.z)\n",
    "                            righthip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "                            lefthip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "                            differenceHips = np.absolute(righthip.z - lefthip.z)\n",
    "                            differenceHipsList.append(differenceHips)\n",
    "                            differenceShouldersList.append(differenceShoulders)\n",
    "                            leftshoulderList.append([leftshoulder.x, leftshoulder.y])\n",
    "                            rightshoulderList.append([rightshoulder.x, rightshoulder.y])\n",
    "                            lefthipList.append([lefthip.x, lefthip.y])\n",
    "                            righthipList.append([righthip.x, righthip.y])\n",
    "\n",
    "                        except:\n",
    "\n",
    "                            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        differenceHipsAverage = np.mean(differenceHipsList)\n",
    "                        differenceShouldersAverage = np.mean(differenceShouldersList)\n",
    "\n",
    "\n",
    "                        slope_shoulder = np.arctan((leftshoulderList[framecounter][1] - rightshoulderList[framecounter][1]) / (leftshoulderList[framecounter][0] - rightshoulderList[framecounter][0]))\n",
    "                        slope_hip = np.arctan((lefthipList[framecounter][1] - righthipList[framecounter][1]) / (lefthipList[framecounter][0] - righthipList[framecounter][0]))\n",
    "\n",
    "                        rate_slope_shoulder = slope_shoulder * fps\n",
    "\n",
    "                        rate_slope_shoulder_length = differenceShouldersAverage * fps\n",
    "                        midpointsholder_p_x = (leftshoulder.x+rightshoulder.x)/2\n",
    "                        midpointsholder_p_y = (leftshoulder.y+rightshoulder.y)/2\n",
    "                        leftsholder_poin=np.array([leftshoulder.x,leftshoulder.y])\n",
    "                        rightsholder_poin=np.array([rightshoulder.x,rightshoulder.y])\n",
    "                        lefthip_poin=np.array([lefthip.x,lefthip.y])\n",
    "                        righthip_poin=np.array([righthip.x,righthip.y])\n",
    "                        midpointsholder_poin=np.array([midpointsholder_p_x,midpointsholder_p_y])\n",
    "                        midpointhip_p_x = (lefthip.x+righthip.x)/2\n",
    "                        midpointhip_p_y = (lefthip.y+righthip.y)/2\n",
    "                        midpointhip_poin=np.array([midpointhip_p_x,midpointhip_p_y])\n",
    "\n",
    "                        s_len_v=np.linalg.norm(leftsholder_poin-rightsholder_poin)\n",
    "                        h_len_v=np.linalg.norm(lefthip_poin-righthip_poin)\n",
    "                        ratio_v=s_len_v/h_len_v\n",
    "                        spinelength_v=np.linalg.norm(midpointsholder_poin-midpointhip_poin)\n",
    "                        framecounter += 1\n",
    "\n",
    "\n",
    "\n",
    "                    #To solve shoulder fluctuation problem with being stuck on one side, we should be able to detect in which phase of the gait cycle the subject is in each frame.\n",
    "                    #In order to determine phase of gait cycle, we have to know the neutral position (standing neutral position) and the corresponding bones positions.\n",
    "                    #From there, we should be able to detect in which phase the subject is in each frame.\n",
    "\n",
    "                        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                                )\n",
    "\n",
    "\n",
    "                        cv2.imshow('Mediapipe Feed', image)\n",
    "                        #image_l.append(image)\n",
    "                        #print(image.shape)\n",
    "\n",
    "                        lsp.append([leftshoulder.x,leftshoulder.y]),rsp.append([rightshoulder.x,rightshoulder.y]),lhp.append([lefthip.x,lefthip.y]),rhp.append([righthip.x,righthip.y]),ratio_l.append(ratio_v),spinelength_l.append(spinelength_v),midpointsholder_l.append([midpointsholder_p_x,midpointsholder_p_y]),midpointhip_l.append([midpointhip_p_x,midpointhip_p_y]),slope_shoulder_l.append(slope_shoulder),slope_hip_l.append(slope_hip),rate_slope_shoulder_l.append(rate_slope_shoulder),rate_slope_shoulder_length_l.append(rate_slope_shoulder_length),s_len.append(s_len_v),h_len.append(h_len_v)\n",
    "                        print('test')\n",
    "                        d=d+1\n",
    "                        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                            break\n",
    "                for k in range(d):\n",
    "                    data={'difference_shoulder': differenceShouldersList,\n",
    "                              'difference_hip': differenceHipsList,\n",
    "                              'Spine_Length':spinelength_l,\n",
    "                              'Shoulder_Length':s_len,\n",
    "                              'Slope_shoulder':slope_shoulder_l,\n",
    "                              'Slope_hip':slope_hip_l}\n",
    "                    npy_path = os.path.join(r'C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training Videos Final', str(x[i]),str(d))\n",
    "                    print(npy_path)\n",
    "                    print(1)\n",
    "                    np.save(npy_path, data)\n",
    "             \n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    " \n",
    "            cap.release()\n",
    "            #print(midpointhip_l)\n",
    "            cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "245ad851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training_Videos_Final\\bad left half\n",
      "C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training_Videos_Final\\bad right half\n",
      "C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training_Videos_Final\\good left half\n",
      "C:\\Users\\surya\\OneDrive\\Desktop\\Sem 2 UB\\ML_Exp\\fp\\Training_Videos_Final\\good right half\n"
     ]
    }
   ],
   "source": [
    "pip_test=get_data(vid_q_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b994c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(out)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q=np.array(os.listdir(os.path.join(DATA_PATH, out))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd81360",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e697406",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, labels =[], []\n",
    "for out in out:\n",
    "    for j in vid_q:\n",
    "        window = []\n",
    "        for sq in range(30):\n",
    "            res = np.load(os.path.join(DATA_PATH, out, str(j), \"{}.npy\".format(sq)))\n",
    "            window.append(res)\n",
    "        seq.append(window)\n",
    "        labels.append(label_map[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=label_map.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFR = [np.array(dataF12),np.array(dataF22),np.array(dataF32),np.array(dataF42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, labels =[], []\n",
    "for i in range(len(out)):\n",
    "    seq.append(dataFR[i])\n",
    "    seq[i]=seq[i][:30]\n",
    "    labels.append(label_map[out[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=np.array(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffab760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84832313",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(seq)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac57506",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir = os.path.join('Logs')\n",
    "#tb_callback = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)\n",
    "#e_callback = TensorBoard(log_dir=log_dir)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2becace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,6)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(Dropout(0.12))\n",
    "# model.add(LSTM(256,return_sequences=True, activation='relu'))  #added layer\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu')) #added layer\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(out.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSProp', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006788f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=1000, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0bbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
