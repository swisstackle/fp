{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b69e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ae6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose=mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9f1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa935641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aef9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.array(['glr','grl','blr', 'brl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3367ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q=['lr.mp4','rl1.mp4','rl2.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0beaf350",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(r'Trainingdata_extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcb2e6",
   "metadata": {},
   "source": [
    "# something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26acd873",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'Trainingdata_extracted\\\\glr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALAINS~1\\AppData\\Local\\Temp/ipykernel_10372/734265752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'Trainingdata_extracted\\\\glr'"
     ]
    }
   ],
   "source": [
    "for out in out:\n",
    "    os.makedirs(os.path.join(DATA_PATH,out))\n",
    "    for i in range(8):\n",
    "        os.makedirs(os.path.join(DATA_PATH, out,str(i)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb940c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q_1 = os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263b7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_i=r'Trainingdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0c0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x):\n",
    "    for i in range(len(x)):\n",
    "        y=os.path.join(data_path_i, str(x[i]))\n",
    "        print(y)\n",
    "        vid=os.listdir(y)\n",
    "        #print(lab_vid_l)\n",
    "        #print(lab_vid_l[0])\n",
    "        for j in range(len(vid)):\n",
    "            #print(vid)\n",
    "            cap = cv2.VideoCapture(os.path.join(data_path_i, x[i],str(vid[j])))\n",
    "            #print(cap)\n",
    "            # used to record the time when we processed last frame\n",
    "            prev_frame_time = 0\n",
    "\n",
    "            # used to record the time at which we processed current frame\n",
    "            new_frame_time = 0\n",
    "            # VIDEO FEED\n",
    "            d=0\n",
    "            try:\n",
    "                with mp_pose.Pose(model_complexity=0,smooth_landmarks=True,min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "                    while cap.isOpened():\n",
    "                        differenceHipsList = [];differenceShouldersList = [];\n",
    "                        leftshoulderList = [];rightshoulderList = [];\n",
    "                        lsp=[];rsp=[];lhp=[];rhp=[];lefthipList = [];\n",
    "                        righthipList = [];midpointsholder_l=[];\n",
    "                        midpointhip_l=[]\n",
    "                        spinelength_l=[]\n",
    "                        s_len=[]\n",
    "                        h_len=[]\n",
    "                        ratio_l=[]\n",
    "                        slope_shoulder_l=[]\n",
    "                        slope_hip_l=[]\n",
    "                        rate_slope_shoulder_l=[]\n",
    "                        rate_slope_shoulder_length_l=[]\n",
    "                        vid_data=[]\n",
    "                        framecounter = 0\n",
    "\n",
    "                        #print('a') \n",
    "                        #print('f')\n",
    "                        ret, frame = cap.read()\n",
    "                        #print('g')\n",
    "                        if not ret:\n",
    "                            #print('a')\n",
    "                            break\n",
    "                        if frame is not None:\n",
    "                            #print('b')\n",
    "                            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                            image.flags.writeable = False\n",
    "                            results = pose.process(image)\n",
    "                            image.flags.writeable = True\n",
    "                            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "                            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                            new_frame_time = time.time()\n",
    "                        # Calculating the fps\n",
    "\n",
    "                        # fps will be number of frame processed in given time frame\n",
    "                        # since their will be most of time error of 0.001 second\n",
    "                        # we will be subtracting it to get more accurate result\n",
    "                            fps = 1 / (new_frame_time - prev_frame_time)\n",
    "                            prev_frame_time = new_frame_time\n",
    "\n",
    "                        # converting the fps into integer\n",
    "                            fps = int(fps)\n",
    "\n",
    "                        # converting the fps to string so that we can display it on frame\n",
    "                        # by using putText function\n",
    "                            fps_1 = str(fps)\n",
    "\n",
    "                        # putting the FPS count on the frame\n",
    "                            cv2.putText(image, fps_1, (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            landmarks = results.pose_landmarks.landmark\n",
    "                            leftshoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "                            rightshoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "                            differenceShoulders = np.absolute(rightshoulder.z - leftshoulder.z)\n",
    "                            righthip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "                            lefthip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "                            differenceHips = np.absolute(righthip.z - lefthip.z)\n",
    "                            differenceHipsList.append(differenceHips)\n",
    "                            differenceShouldersList.append(differenceShoulders)\n",
    "                            leftshoulderList.append([leftshoulder.x, leftshoulder.y])\n",
    "                            rightshoulderList.append([rightshoulder.x, rightshoulder.y])\n",
    "                            lefthipList.append([lefthip.x, lefthip.y])\n",
    "                            righthipList.append([righthip.x, righthip.y])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            differenceHipsAverage = np.mean(differenceHipsList)\n",
    "                            differenceShouldersAverage = np.mean(differenceShouldersList)\n",
    "\n",
    "\n",
    "                            slope_shoulder = np.arctan((leftshoulderList[framecounter][1] - rightshoulderList[framecounter][1]) / (leftshoulderList[framecounter][0] - rightshoulderList[framecounter][0]))\n",
    "                            slope_hip = np.arctan((lefthipList[framecounter][1] - righthipList[framecounter][1]) / (lefthipList[framecounter][0] - righthipList[framecounter][0]))\n",
    "\n",
    "                            rate_slope_shoulder = slope_shoulder * fps\n",
    "\n",
    "                            rate_slope_shoulder_length = differenceShouldersAverage * fps\n",
    "                            midpointsholder_p_x = (leftshoulder.x+rightshoulder.x)/2\n",
    "                            midpointsholder_p_y = (leftshoulder.y+rightshoulder.y)/2\n",
    "                            leftsholder_poin=np.array([leftshoulder.x,leftshoulder.y])\n",
    "                            rightsholder_poin=np.array([rightshoulder.x,rightshoulder.y])\n",
    "                            lefthip_poin=np.array([lefthip.x,lefthip.y])\n",
    "                            righthip_poin=np.array([righthip.x,righthip.y])\n",
    "                            midpointsholder_poin=np.array([midpointsholder_p_x,midpointsholder_p_y])\n",
    "                            midpointhip_p_x = (lefthip.x+righthip.x)/2\n",
    "                            midpointhip_p_y = (lefthip.y+righthip.y)/2\n",
    "                            midpointhip_poin=np.array([midpointhip_p_x,midpointhip_p_y])\n",
    "\n",
    "                            s_len_v=np.linalg.norm(leftsholder_poin-rightsholder_poin)\n",
    "                            h_len_v=np.linalg.norm(lefthip_poin-righthip_poin)\n",
    "                            ratio_v=s_len_v/h_len_v\n",
    "                            spinelength_v=np.linalg.norm(midpointsholder_poin-midpointhip_poin)\n",
    "                            framecounter += 1\n",
    "\n",
    "\n",
    "\n",
    "                        #To solve shoulder fluctuation problem with being stuck on one side, we should be able to detect in which phase of the gait cycle the subject is in each frame.\n",
    "                        #In order to determine phase of gait cycle, we have to know the neutral position (standing neutral position) and the corresponding bones positions.\n",
    "                        #From there, we should be able to detect in which phase the subject is in each frame.\n",
    "\n",
    "                            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                                    mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                                    mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                                    )\n",
    "\n",
    "\n",
    "                            cv2.imshow('Mediapipe Feed', image)\n",
    "                            #image_l.append(image)\n",
    "                            #print(image.shape)\n",
    "\n",
    "                            lsp.append([leftshoulder.x,leftshoulder.y]),rsp.append([rightshoulder.x,rightshoulder.y]),lhp.append([lefthip.x,lefthip.y]),rhp.append([righthip.x,righthip.y]),ratio_l.append(ratio_v),spinelength_l.append(spinelength_v),midpointsholder_l.append([midpointsholder_p_x,midpointsholder_p_y]),midpointhip_l.append([midpointhip_p_x,midpointhip_p_y]),slope_shoulder_l.append(slope_shoulder),slope_hip_l.append(slope_hip),rate_slope_shoulder_l.append(rate_slope_shoulder),rate_slope_shoulder_length_l.append(rate_slope_shoulder_length),s_len.append(s_len_v),h_len.append(h_len_v)\n",
    "                            d=d+1\n",
    "                            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                                continue\n",
    "                        data={'difference_shoulder': differenceShouldersList,\n",
    "                                      'difference_hip': differenceHipsList,\n",
    "                                      'Spine_Length':spinelength_l,\n",
    "                                      'Shoulder_Length':s_len,\n",
    "                                      'Slope_shoulder':slope_shoulder_l,\n",
    "                                      'Slope_hip':slope_hip_l}\n",
    "                        data_n=np.array(data)\n",
    "                        npy_path_m = os.path.join(data_path_i, x[i])\n",
    "\n",
    "                        npy_path = os.path.join(npy_path_m,str(j))\n",
    "\n",
    "                        vid_data.append([npy_path,data_n])\n",
    "            except:\n",
    "                 pass\n",
    "             \n",
    " \n",
    "            cap.release()\n",
    "            #print(midpointhip_l)\n",
    "            cv2.destroyAllWindows()\n",
    "    return vid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "245ad851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingdata\\blr\n",
      "Trainingdata\\brl\n",
      "Trainingdata\\glr\n",
      "Trainingdata\\grl\n"
     ]
    }
   ],
   "source": [
    "vid_data_list=get_data(vid_q_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b994c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(out)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q=np.array(os.listdir(os.path.join(DATA_PATH, out))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd81360",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e697406",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, labels =[], []\n",
    "for out in out:\n",
    "    for j in vid_q:\n",
    "        window = []\n",
    "        for sq in range(30):\n",
    "            res = np.load(os.path.join(DATA_PATH, out, str(j), \"{}.npy\".format(sq)))\n",
    "            window.append(res)\n",
    "        seq.append(window)\n",
    "        labels.append(label_map[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=label_map.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFR = [np.array(dataF12),np.array(dataF22),np.array(dataF32),np.array(dataF42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, labels =[], []\n",
    "for i in range(len(out)):\n",
    "    seq.append(dataFR[i])\n",
    "    seq[i]=seq[i][:30]\n",
    "    labels.append(label_map[out[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=np.array(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffab760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84832313",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(seq)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac57506",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir = os.path.join('Logs')\n",
    "#tb_callback = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)\n",
    "#e_callback = TensorBoard(log_dir=log_dir)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2becace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,6)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(Dropout(0.12))\n",
    "# model.add(LSTM(256,return_sequences=True, activation='relu'))  #added layer\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu')) #added layer\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(out.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSProp', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006788f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=1000, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0bbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
